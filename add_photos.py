import time
import requests
import pandas as pd

INPUT_FILE = "places_semicolon.csv"
OUTPUT_FILE = "places_semicolon.csv"

HEADERS = {"User-Agent": "AI Travel Crimea Bot/1.0 (https://t.me/yourbot)"}

def find_image_wikipedia(query: str):
    """–ò—â–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –í–∏–∫–∏–ø–µ–¥–∏–∏"""
    try:
        url = "https://ru.wikipedia.org/w/api.php"
        params = {
            "action": "query",
            "prop": "pageimages",
            "format": "json",
            "piprop": "original",
            "titles": query
        }
        res = requests.get(url, params=params, headers=HEADERS, timeout=10)
        data = res.json()
        pages = data.get("query", {}).get("pages", {})
        for _, page in pages.items():
            if "original" in page:
                return page["original"]["source"]
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ {query}: {e}")
    return None

def main():
    df = pd.read_csv(INPUT_FILE, sep=";")
    if "photo" not in df.columns:
        df["photo"] = ""

    for i, row in df.iterrows():
        if isinstance(row.get("photo"), str) and row["photo"].startswith("http"):
            continue  # —É–∂–µ –µ—Å—Ç—å —Ñ–æ—Ç–æ
        query = f"{row['name']} {row['city']} –ö—Ä—ã–º"
        print(f"üîé –ò—â—É —Ñ–æ—Ç–æ –¥–ª—è: {query}")
        img = find_image_wikipedia(query)
        if not img:
            # –µ—Å–ª–∏ –Ω–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –±–µ–∑ –≥–æ—Ä–æ–¥–∞
            img = find_image_wikipedia(row["name"])
        if img:
            df.at[i, "photo"] = img
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ñ–æ—Ç–æ: {img}")
        else:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–æ—Ç–æ –¥–ª—è {query}")
        time.sleep(0.5)

    df.to_csv(OUTPUT_FILE, sep=";", index=False)
    print(f"\nüíæ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
